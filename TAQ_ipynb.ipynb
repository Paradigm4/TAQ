{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example SciDB queries for trade and quote data\n",
    "\n",
    "This iPython Notebook achieves the following:\n",
    " - Loading NYSE market data\n",
    " - Bar building (open high low close)\n",
    " - Building minute bars\n",
    " - Calculating VWAP\n",
    " - As-Of join\n",
    " - Running ad-hoc queries (e.g. checking for Regulation NMS/Compliance)\n",
    "\n",
    "The most updated version of this code is maintained at https://github.com/Paradigm4/TAQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the data\n",
    "\n",
    " - This notebook uses NYSE market made available from http://www.nyxdata.com/ \n",
    " - The data file format specification is available from: http://www.nyxdata.com/doc/224904\n",
    " - The data license governs that we cannot redistribute the data as part of this AMI. Hence the first step is to download the data via FTP. \n",
    " \n",
    "## Download speeds vary. \n",
    " - To download the data quickly and start the SciDB processing, we have provided a `FullDownload` flag (the default value of `False` will run only a partial download)\n",
    " - If you want to download the entire day's data and load it onto SciDB, set `FullDownload` to `True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FullDownload=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the `NBBO` data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: /home/scidb/.curlrc:1: warning: 'cafile' had unsupported trailing \n",
      "Warning: garbage\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 13.6M  100 13.6M    0     0  1570k      0  0:00:08  0:00:08 --:--:-- 1701k\n"
     ]
    }
   ],
   "source": [
    "if ~FullDownload:\n",
    "    !curl -r 0-14312312 \\\n",
    "        ftp://ftp.nyxdata.com/Historical%20Data%20Samples/Daily%20TAQ/EQY_US_ALL_NBBO_20131218.zip \\\n",
    "        > /tmp/EQY_US_ALL_NBBO_20131218.zip\n",
    "else:\n",
    "    !curl \\\n",
    "        ftp://ftp.nyxdata.com/Historical%20Data%20Samples/Daily%20TAQ/EQY_US_ALL_NBBO_20131218.zip \\\n",
    "        > /tmp/EQY_US_ALL_NBBO_20131218.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, download the `trades` data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: /home/scidb/.curlrc:1: warning: 'cafile' had unsupported trailing \n",
      "Warning: garbage\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 7083k  100 7083k    0     0  1555k      0  0:00:04  0:00:04 --:--:-- 1687k\n"
     ]
    }
   ],
   "source": [
    "if ~FullDownload:\n",
    "    !curl -r 0-7253059 \\\n",
    "        ftp://ftp.nyxdata.com/Historical%20Data%20Samples/Daily%20TAQ/EQY_US_ALL_TRADE_20131218.zip \\\n",
    "            > /tmp/EQY_US_ALL_TRADE_20131218.zip\n",
    "else:\n",
    "    !curl \\\n",
    "        ftp://ftp.nyxdata.com/Historical%20Data%20Samples/Daily%20TAQ/EQY_US_ALL_TRADE_20131218.zip \\\n",
    "            > /tmp/EQY_US_ALL_TRADE_20131218.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data into ScIDB\n",
    "\n",
    "The `trades_load.sh` and `trades_redim.sh` scripts load the `EQY_US_ALL_TRADE_20131218.zip` data and redimensions it into a `ms` (time) by `symbol_index` by `synthetic` 3-d SciDB array. \n",
    "\n",
    "The script also creates an auxiliary mapping array named `tkr` between string ticker symbol and integer symbol index.\n",
    "\n",
    "The `quotes_load.sh` and `quotes_redim.sh` script does the same thing but for the `EQY_US_ALL_NBBO` quote data file.\n",
    "\n",
    "## Note on loaders\n",
    "\n",
    "The loaders shown above use the most generic loaders available in SciDB community edition. SciDB can achieve much higher load rates using Enterprise edition plugins.  \n",
    "\n",
    "## Steps to load `trades` data\n",
    "\n",
    " - Run the following to load and redimension the example data\n",
    " - For a first run, we load the first 500k elements of the `trades` data. \n",
    " - Later, we suggest that you run the entire download and load (set `FullDownload` to `True`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading first 500000 records\n",
      "Trades file:\n",
      "/tmp/EQY_US_ALL_TRADE_20131218.zip\n",
      "Query was executed successfully\n",
      "Query was executed successfully\n",
      "Query was executed successfully\n",
      "\n",
      "Query was executed successfully\n",
      "{i} count\n",
      "{0} 39\n",
      "Query was executed successfully\n",
      "Query was executed successfully\n",
      "Query was executed successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "# Load into a flat file\n",
    "if ~FullDownload:\n",
    "    proc = subprocess.Popen([\"./trades_load.sh\", \"/tmp/EQY_US_ALL_TRADE_20131218.zip\", \"500000\"], stdout=subprocess.PIPE)\n",
    "else:\n",
    "    proc = subprocess.Popen([\"./trades_load.sh\", \"/tmp/EQY_US_ALL_TRADE_20131218.zip\"], stdout=subprocess.PIPE)\n",
    "output1 = proc.stdout.read()\n",
    "# Redimension to actionable SciDB array\n",
    "proc = subprocess.Popen(\"./trades_redim.sh\", stdout=subprocess.PIPE)\n",
    "output2 = proc.stdout.read()\n",
    "print(output1 + '\\n' + output2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps to load `quotes` data\n",
    "\n",
    " - Again, for a first run, we load the first 1M elements of the `quotes` data\n",
    " - Later, we suggest that you run the entire download and load (set `FullDownload` to `True`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading first 1000000 records\n",
      "Quotes file:\n",
      "/tmp/EQY_US_ALL_NBBO_20131218.zip\n",
      "Query was executed successfully\n",
      "Query was executed successfully\n",
      "\n",
      "Query was executed successfully\n",
      "Query was executed successfully\n",
      "Query was executed successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load into a flat file\n",
    "if ~FullDownload:\n",
    "    proc = subprocess.Popen([\"./quotes_load.sh\", \"/tmp/EQY_US_ALL_NBBO_20131218.zip\",  \"1000000\"], stdout=subprocess.PIPE)\n",
    "else:\n",
    "    proc = subprocess.Popen([\"./quotes_load.sh\", \"/tmp/EQY_US_ALL_NBBO_20131218.zip\"], stdout=subprocess.PIPE)\n",
    "output1 = proc.stdout.read()\n",
    "# Redimension to actionable SciDB array\n",
    "proc = subprocess.Popen(\"./quotes_redim.sh\", stdout=subprocess.PIPE)\n",
    "output2 = proc.stdout.read()\n",
    "print(output1 + '\\n' + output2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecting to the database\n",
    "\n",
    "Then let's run some queries on the loaded trades and quote (TAQ) data directly from the Python interface.\n",
    "First let us set up the connectivity to the database (and also import some useful libraries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scidb/anaconda2/lib/python2.7/site-packages/scidb_py-15.12.dev0-py2.7.egg/scidbpy/parse.py:135: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "/home/scidb/anaconda2/lib/python2.7/site-packages/scidb_py-15.12.dev0-py2.7.egg/scidbpy/parse.py:133: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scidbpy import connect\n",
    "import time\n",
    "sdb = connect(\"http://localhost:8080\")\n",
    "afl = sdb.afl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, associate Python objects with SciDB arrays (no data transfers yet -- just connections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trades = sdb.wrap_array('trades')\n",
    "quotes = sdb.wrap_array('quotes')\n",
    "tkr = sdb.wrap_array('tkr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded library: limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scidb/anaconda2/lib/python2.7/site-packages/scidb_py-15.12.dev0-py2.7.egg/scidbpy/parse.py:128: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symbol_index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AA    PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AADR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAIT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                symbol\n",
       "symbol_index          \n",
       "0                    A\n",
       "1                   AA\n",
       "2             AA    PR\n",
       "3                 AADR\n",
       "4                 AAIT"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if subprocess.call([\"/opt/scidb/15.12/bin/iquery\", \"-aq\", \"load_library('limit')\"]) == 0:\n",
    "    print('loaded library: limit')\n",
    "else:\n",
    "    print('''requires user to install the `limit` library. \n",
    "            See https://github.com/Paradigm4/limit. \n",
    "            Otherwise, use the slower version: tkr.todataframe().head()''')\n",
    "tkr.limit(5).todataframe() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking up trades by symbol string\n",
    "\n",
    "Join with the auxiliary `tkr` array to look up data by ticker symbol name. Here are examples that count the number of trades and quotes for 'ABBV'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56545 trades for ABBV \n",
      "89867 quotes for ABBV \n"
     ]
    }
   ],
   "source": [
    "symbol = \"ABBV\"\n",
    "print(\"%d trades for %s \" % (sdb.merge(trades,\n",
    "            tkr.filter(\"symbol='%s'\" % symbol)\n",
    "          ).nonempty(), symbol))\n",
    "print(\"%d quotes for %s \" % (sdb.merge(quotes,\n",
    "            tkr.filter(\"symbol='%s'\" % symbol)\n",
    "          ).nonempty(), symbol))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected we see more quotes than trades for this instrument. \n",
    "\n",
    "The above join showed us that there are 56545 trades for the ticker `ABBV`. We can also retrieve those trades using the `between` statement, but we need to know the `symbol_index`, which we find by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symbol_index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ABBV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             symbol\n",
       "symbol_index       \n",
       "22             ABBV"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tkr.filter(\"symbol='%s'\" % symbol).todataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find the dimensions of the array trades as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'synthetic', u'symbol_index', u'tm']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trades.dim_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we then run the `between` statement using the following syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56545"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trades.between('null', 22, 'null', 'null', 22, 'null').nonempty()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The order of arguments follows the dimensions of the array:\n",
    " - the `trades` array has three dimensions (`synthetic, symbol_index, tm`)\n",
    " - the `between` expects pairs of arguments for `[start, end]`\n",
    " - hence six arguments for the `between` command above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing VWAP\n",
    "\n",
    "Let's turn to another common kind of operation, computing volume-weighted average price (VWAP). We'll compute it for every instrument across their raw trade data in the array trades, and store the result into a new array called 'VWAP'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>numerator</th>\n",
       "      <th>denominator</th>\n",
       "      <th>vwap</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>synthetic</th>\n",
       "      <th>symbol_index</th>\n",
       "      <th>tm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">13</th>\n",
       "      <th>14781433</th>\n",
       "      <td>2780</td>\n",
       "      <td>5</td>\n",
       "      <td>556.000000</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14833032</th>\n",
       "      <td>58375</td>\n",
       "      <td>105</td>\n",
       "      <td>555.952381</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15477542</th>\n",
       "      <td>169209</td>\n",
       "      <td>305</td>\n",
       "      <td>554.783607</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15643058</th>\n",
       "      <td>224698</td>\n",
       "      <td>405</td>\n",
       "      <td>554.809877</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15689610</th>\n",
       "      <td>502008</td>\n",
       "      <td>905</td>\n",
       "      <td>554.704972</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 numerator  denominator        vwap symbol\n",
       "synthetic symbol_index tm                                                 \n",
       "0         13           14781433       2780            5  556.000000   AAPL\n",
       "                       14833032      58375          105  555.952381   AAPL\n",
       "                       15477542     169209          305  554.783607   AAPL\n",
       "                       15643058     224698          405  554.809877   AAPL\n",
       "                       15689610     502008          905  554.704972   AAPL"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vwap = trades.apply('pv', 'price*volume')\n",
    "vwap = sdb.afl.cumulate(vwap, \\\n",
    "                        'sum(pv) as numerator', \\\n",
    "                        'sum(volume) as denominator', 'tm')\n",
    "vwap = vwap.apply('vwap', 'numerator/denominator')\n",
    "sdb.merge(vwap, tkr[tkr == 'AAPL']).\\\n",
    "    limit(5).\\\n",
    "    todataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing minute bars\n",
    "\n",
    "The trade data are now organized by symbol, time, and a synthetic coordinate that separates collisions (due to, say exchanges) in a sparse array.\n",
    "\n",
    "We need some extra aggregates from the `axial_aggregate` plugin -- load that:\n",
    "\n",
    "## Load `axial_aggregate` library\n",
    "\n",
    "We load the `axial_aggregate` library for the following calculations. The library is only available to Enterprise customers. Contact Paradigm4 for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The library is only available to Enterprise customers. Contact Paradigm4 for more details. \n"
     ]
    }
   ],
   "source": [
    "if subprocess.call([\"/opt/scidb/15.12/bin/iquery\", \"-aq\", \"load_library('axial_aggregate')\"]) !=0: \n",
    "    print('The library is only available to Enterprise customers. Contact Paradigm4 for more details. ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following query computes and store one-minute open/high/low/close bars from these data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SciDBQueryError",
     "evalue": "UserQueryException in file: src/query/Expression.cpp function: internalCompile line: 567\nError id: scidb::SCIDB_SE_QPROC::SCIDB_LE_FUNCTION_NOT_FOUND\nError description: Query processor error. Function 'tuple(int64, double)' not found.\nstore(regrid(apply(trades,timeprice,tuple(tm,price)),1,1,60000,axial_first(timeprice) as open,max(price) as high,min(price) as low,axial_last(timeprice) as close), py1460574445841464744_00035)\n                                    ^^^^^^^^^^^^^^^",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSciDBQueryError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-f5f2bd5a2c8b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[1;34m'axial_last(timeprice) as close'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m           )\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mminute_bars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mminute_bars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/scidb/anaconda2/lib/python2.7/site-packages/scidb_py-15.12.dev0-py2.7.egg/scidbpy/scidbarray.pyc\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, out, store, **kwargs)\u001b[0m\n\u001b[0;32m   1028\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1029\u001b[0m         \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'store({q}, {name})'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1030\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/scidb/anaconda2/lib/python2.7/site-packages/scidb_py-15.12.dev0-py2.7.egg/scidbpy/interface.pyc\u001b[0m in \u001b[0;36m_execute_query\u001b[1;34m(self, query, response, n, fmt, **kwargs)\u001b[0m\n\u001b[0;32m   1754\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shim_release_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_invalid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1755\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1756\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shim_execute_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrelease\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1757\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1758\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/scidb/anaconda2/lib/python2.7/site-packages/scidb_py-15.12.dev0-py2.7.egg/scidbpy/interface.pyc\u001b[0m in \u001b[0;36m_shim_execute_query\u001b[1;34m(self, session_id, query, save, release, **kwargs)\u001b[0m\n\u001b[0;32m   1828\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1829\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1830\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shim_urlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1831\u001b[0m             \u001b[0mquery_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1832\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/scidb/anaconda2/lib/python2.7/site-packages/scidb_py-15.12.dev0-py2.7.egg/scidbpy/interface.pyc\u001b[0m in \u001b[0;36m_shim_urlopen\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m   1790\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1791\u001b[0m             \u001b[0mError\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSHIM_ERROR_DICT\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1792\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1794\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSciDBQueryError\u001b[0m: UserQueryException in file: src/query/Expression.cpp function: internalCompile line: 567\nError id: scidb::SCIDB_SE_QPROC::SCIDB_LE_FUNCTION_NOT_FOUND\nError description: Query processor error. Function 'tuple(int64, double)' not found.\nstore(regrid(apply(trades,timeprice,tuple(tm,price)),1,1,60000,axial_first(timeprice) as open,max(price) as high,min(price) as low,axial_last(timeprice) as close), py1460574445841464744_00035)\n                                    ^^^^^^^^^^^^^^^"
     ]
    }
   ],
   "source": [
    "minute_bars = trades.apply('timeprice', 'tuple(tm,price)')\n",
    "minute_bars = sdb.afl.regrid(minute_bars, 1, 1, 60000,\n",
    "            'axial_first(timeprice) as open',\n",
    "            'max(price) as high',\n",
    "            'min(price) as low',\n",
    "            'axial_last(timeprice) as close'\n",
    "          )\n",
    "minute_bars = minute_bars.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the calculation was done for all the tickers in parallel. \n",
    "\n",
    "We then download all the minute-bars data for ticker `AAN` into a Pandas dataframe. This shows the capability to download data into Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mb1 = sdb.merge(minute_bars, \n",
    "                tkr[tkr == \"AAN\"]).todataframe()\n",
    "mb1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note! That 570 minutes = 9:30 AM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.finance import candlestick_ohlc\n",
    "\n",
    "# Split the dimensions to get the minute co-ordinates\n",
    "l1, l2,l3 = zip(*mb1.index.get_values())\n",
    "# unify into a nparray of tuples for use in candlestick graph\n",
    "q2 = zip(l3, mb1.open, mb1.high, mb1.low, mb1.close)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.subplots_adjust(bottom=0.2)\n",
    "fig.suptitle('Minute bars (OHLC): Symbol \\'AAN\\' ', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('minutes')\n",
    "ax.set_ylabel('$')\n",
    "\n",
    "candlestick_ohlc(ax, q2[15:30], width=0.6)\n",
    "\n",
    "ax.autoscale_view()\n",
    "plt.setp(plt.gca().get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AsOf join\n",
    "\n",
    "The `asof` operator joins trade data with quote data. At time points where quote data is not available, the last known value is looked up and filled in. This is sometimes also called a 'last value carry forward' join or 'piecewise constant interpolation join'.\n",
    "\n",
    "The syntax is:\n",
    "```\n",
    "asof(A, B [, aggrDim [, missingCode [, preserveNull]])\n",
    "```\n",
    "\n",
    "where the inputs are:\n",
    "- `A & B`: two arrays that have the same dimensionality;\n",
    "- `aggrDim`: the dimension in A along which to find last_value. Default is the last dimension.\n",
    "- `missingCode`: the missing code to use, when an A record cannot be found. Default is 0.\n",
    "- `preserveNull`: whether to preserve or skip past nulls in the left array. Default is to preserve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we run the `asof` join, we have to take care of collisions in the timestamp dimension. Times were recorded in milliseconds and there were quite a lot of collisions in the data, as shown by the partial result below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quotes.aggregate('count(*)', 'synthetic').todataframe().tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above result shows that there are up to 48 collisions at a certain timestamp for the loaded data. \n",
    "\n",
    "We can take care of the synthetic dimensions in multiple ways. In this example, we choose to convert the millisecond timestamp to an artificial microsecond resolution. \n",
    "\n",
    "## Taking care of synthetics in the quotes array \n",
    "\n",
    "We first find the minimum sequence number at each symbol index and timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "minseq = quotes.aggregate('min(sequence_number)', 'symbol_index', 'tm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then join it back with the quotes array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joined = sdb.merge(quotes, minseq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we calculate an ordered index at each colliding timestamp, and then redimension to an array that has an artifical but correctly ordered microsecond timestamp resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quotes2 = joined.apply('subi', 'sequence_number - sequence_number_min')\\\n",
    "            .apply('tm_us', 'tm*1000 + subi')\\\n",
    "            .redimension('''<tm:int64, ask_price:double,ask_size:int64,\n",
    "                         bid_price:double,bid_size:int64,sequence_number:int64,\n",
    "                         condition:string,exchange:string>\n",
    "                         [symbol_index=0:*,10,0, tm_us=0:*,86400000000,0]''')\n",
    "quotes2 = quotes2.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we do the same to the trades array, but we add an offset of 500 to the artificial microsecond timestamp dimension. That means we can handle upto 499 collisions at any millisecond in our new artificial timestamp dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "minseq = trades.aggregate('min(sequence_number)', 'symbol_index', 'tm')\n",
    "joined = sdb.merge(trades, minseq)\n",
    "trades2 = joined.apply('subi', 'sequence_number - sequence_number_min')\\\n",
    "            .apply('tm_us', 'tm*1000 + 500 + subi')\\\n",
    "            .redimension('''<tm:int64, price:double,volume:int64,\n",
    "                            sequence_number:int64,condition:string,\n",
    "                            exchange:string>\n",
    "                         [symbol_index=0:*,10,0, tm_us=0:*,86400000000,0]''')\n",
    "trades2 = trades2.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we run the `asof` join and make some simple checks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "asof1 = sdb.afl.asof('%s as A' % quotes2.name, trades2, 'A.tm_us', 5, 'false')\n",
    "asof1 = asof1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('\\n# of elements in the joined result:')\n",
    "print(asof1.nonempty())\n",
    "print('\\nThe head() of the joined array')\n",
    "sdb.merge(asof1.project('tm', 'ask_price', 'ask_size', 'bid_price', 'bid_size', 'tm_2', 'price', 'volume'), \\\n",
    "            tkr[tkr == 'AAN']).\\\n",
    "            limit(20).\\\n",
    "            todataframe().tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RegNMS (Compliance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally run some interesting analysis on the result of the As Of join. \n",
    "\n",
    "First, filter the joined quotes for inconsistencies e.g. where the ask price was lower than the bid price. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sdb.merge(asof1.filter('ask_price < bid_price')\\\n",
    "        .project('tm', 'ask_price', 'ask_size', 'bid_price', 'bid_size', 'tm_2', 'price', 'volume'), \\\n",
    "        tkr[tkr=='AAN'])\\\n",
    "        .limit(5)\\\n",
    "        .todataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus there are no inconsistent quotes.\n",
    "\n",
    "Next, check for trades that occurred outside the ask-bid spread. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sdb.merge(asof1.filter('price < bid_price or price > ask_price')\\\n",
    "        .project('tm', 'ask_price', 'ask_size', 'bid_price', 'bid_size', 'tm_2', 'price', 'volume'), \\\n",
    "        tkr[tkr=='AAN']).\\\n",
    "        limit(5).\\\n",
    "        todataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we found some joined results where the traded price lies outside the range between bids and asks. \n",
    "\n",
    "# Not shown here\n",
    "\n",
    "Using these same building blocks of array storage, multidimensional joins, linear algebra, R/Python interfaces and advanced extensibility, SciDB can perform a vast universe of various tasks, all of which would simply not fit into a single AMI. Here’s a partial list of other analyses we have performed together with some of our customers and partners:\n",
    "\n",
    "1. Customized load scripts\n",
    "     - Parallel binary load: Parallel ingest of files located across the storage cluster\n",
    "     - Domain specific loader modules: Loaders optimized for specific data-type that is to be ingested\n",
    "2. Order book building\n",
    "     - Order book building from TAQ data\n",
    "     - Order book aggregation (NBBO) from multiple books\n",
    "3. Other finance workflows\n",
    "     - Portfolio risk analysis\n",
    "     - Transaction cost analysis\n",
    "     - Advanced tick analytics\n",
    "     - Bi-temporal data handling\n",
    "     - Option volatility surface studies\n",
    "4. Interfacing with compute grids\n",
    "     - Parallel download to 3rd party clients (Python, R) to support elastic compute grids \n",
    "5. Enterprise-Level Features\n",
    "     - Elasticity: adding new nodes to a live cluster with negligible downtime. The data can be redistributed while the cluster remains available for queries.\n",
    "     - Namespaces and Permissions: granting certain database users permissions over specific arrays - to control access and share more effectively and securely.\n",
    "     - Replication: storing extra copies of data to protect against disk failure. \n",
    "     - System monitoring: a mechanism that detects the loss of a host and, if the failure is intermittent, automatically returns the system to working state\n",
    "6. Additional functionality: large sparse SVD, GLM, MKL-accelerated linear algebra\n",
    "\n",
    "For questions about any of these, items reach out to us at `FinancialMarkets@paradigm4.com`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
